{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Analysis for Modal Parameter Linear Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Install the `sample` package and its dependencies.\n",
    "The extras will install dependencies for helper functions such as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!$sys.executable -m pip install -qU lim-sample[notebooks,plots]==2.1.0\n",
    "import sample\n",
    "\n",
    "sample(logo=dict(size_inches=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test audio\n",
    "We will synthesize a modal-like sound with three modal frequencies using simple additive synthesis.  \n",
    "Also, we will add a gaussian noise at -45 dB SNR to mimic a bad recording environment.  \n",
    "Sampling frequency is 44100 Hz and the duration is 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython import display as ipd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sample.sample import additive_synth\n",
    "from sample.utils import dsp as dsp_utils\n",
    "\n",
    "\n",
    "def resize(diag: float = 8.485, aspect: float = 1, shape=(1, 1)):\n",
    "  plt.gcf().set_size_inches(\n",
    "      diag * np.true_divide([aspect, 1], np.sqrt(aspect * aspect + 1)) *\n",
    "      np.flip(shape))\n",
    "\n",
    "\n",
    "ground_truth = {\n",
    "    \"freqs\": [440, 1103, 1097],\n",
    "    \"decays\": [1, 0.75, 2],\n",
    "    \"amps\": [1, 0.8, 0.2],\n",
    "}\n",
    "ground_truth[\"amps\"] = np.array(ground_truth[\"amps\"]) / sum(\n",
    "    ground_truth[\"amps\"])\n",
    "\n",
    "fs = 44100\n",
    "x = additive_synth(np.arange(int(2 * fs)) / fs, **ground_truth)\n",
    "\n",
    "# Add noise\n",
    "np.random.seed(42)\n",
    "x += np.random.randn(np.size(x)) * dsp_utils.db2a(-45)\n",
    "x /= np.max(np.abs(x))\n",
    "t = np.arange(x.size) / fs\n",
    "\n",
    "ipd.display(ipd.Audio(x, rate=fs))\n",
    "\n",
    "plt.plot(t, x, alpha=.5, zorder=100)\n",
    "plt.grid()\n",
    "resize(aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface\n",
    "Using the SAMPLE model is simplified by a scikit-learn-like API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sample.SAMPLE(sinusoidal__tracker__max_n_sines=16,\n",
    "                      sinusoidal__tracker__peak_threshold=-30,\n",
    "                      sinusoidal__intermediate__save=True)\n",
    "model.fit(x, sinusoidal__tracker__fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinusoidal Model\n",
    "SAMPLE is based on Serra's *Spectral Modelling Synthesis* (SMS),\n",
    "an analysis and synthesis system for musical sounds based\n",
    "on the decomposition of the sound into a deterministic\n",
    "sinusoidal and a stochastic component.\n",
    "\n",
    "The main components of the sinusoidal analysis are the peak detection\n",
    "and the peak continuation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT\n",
    "The peak detection/continuation algorithm is based on an analysis of the Short-Time Fourier Transform. Zero-phase windowing is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import plots\n",
    "\n",
    "stft = np.array([mx for mx, _ in model.sinusoidal.intermediate[\"stft\"]]).T\n",
    "f = fs * np.arange(stft.shape[0]) / model.sinusoidal.w.size\n",
    "\n",
    "plots.tf_plot(stft,\n",
    "              tlim=t[[0, -1]],\n",
    "              flim=f[[0, -1]],\n",
    "              ylim=[0, 2000],\n",
    "              aspect_ratio=16 / 9)\n",
    "resize(aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak detection\n",
    "The peak detection algorithm detects peaks in each STFT frame of the analysed\n",
    "sound as a local maximum in the magnitude spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx, px = model.sinusoidal.intermediate[\"stft\"][0]\n",
    "ploc, pmag, pph = model.sinusoidal.intermediate[\"peaks\"][0]\n",
    "\n",
    "ax = plt.subplot(121)\n",
    "plt.fill_between(f, np.full(mx.shape, -120), mx, alpha=.1)\n",
    "plt.plot(f, mx)\n",
    "plt.scatter(ploc * fs / model.sinusoidal.w.size, pmag, c=\"C0\")\n",
    "plt.ylim([-60, plt.ylim()[1]])\n",
    "plt.grid()\n",
    "plt.title(\"magnitude\")\n",
    "\n",
    "plt.subplot(122, sharex=ax)\n",
    "plt.plot(f, px)\n",
    "plt.scatter(ploc * fs / model.sinusoidal.w.size, pph)\n",
    "plt.ylim([np.min(px[f < 2000]), np.max(px[f < 2000])])\n",
    "plt.grid()\n",
    "plt.title(\"phase\")\n",
    "plt.xlim([0, 2000])\n",
    "resize(shape=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak continuation\n",
    "The peak continuation algorithm organizes the peaks into temporal tracks,\n",
    "with every track representing the time-varying behaviour of a partial.\n",
    "For every peak in a trajectory, the instantaneous frequency, magnitude\n",
    "and phase are stored to allow further manipulation and resynthesis.\n",
    "\n",
    "The general-purpose SMS method enables recycling of the peak tracks data structures: if one trajectory\n",
    "becomes inactive, it can be later picked up when a newly detected partial arises.\n",
    "Our implementation doesn't allow this.\n",
    "\n",
    "Moreover, two tracks that do not overlap in time but have approximately the same\n",
    "average frequency can be considered as belonging to the same partial and merged into the same track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.sine_tracking_2d(model)\n",
    "resize(shape=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.sine_tracking_3d(model)\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Partials of a modal impact sound are characterized by exponentially decaying amplitudes.\n",
    "Our model for modal partials is\n",
    "$$x(t) = m\\cdot e^{-2\\frac{t}{d}}\\cdot \\sin{\\left(2\\pi f t + \\phi\\right)}$$\n",
    "\n",
    "The magnitude in decibels is a linear funtion of time\n",
    "$$m_{dB}(t) = 20\\log_{10}{\\left(m\\cdot e^{-2\\frac{t}{d}}\\right)} = 20\\log_{10}{m} - 40\\frac{\\log_{10}{e}}{d} \\cdot t$$\n",
    "\n",
    "$$k = - 40\\frac{\\log_{10}{e}}{d}$$\n",
    "$$q = 20\\log_{10}{m}$$\n",
    "\n",
    "$$m_{dB}(t) = kt + q$$\n",
    "\n",
    "We use linear regression to find an initial estimate of the parameters $k$ and $q$ from the magnitude tracks. Then, we refine the estimate by fitting a semi-linear *hinge* function. Amplitude is then doubled to compensate for the fact that we are looking at only half of the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = np.arange(x.size) / fs\n",
    "for i, ((f, d, a),\n",
    "        t) in enumerate(zip(model.param_matrix_.T, model.sinusoidal.tracks_)):\n",
    "  c = \"C{}\".format(i)\n",
    "  t_t = (t[\"start_frame\"] +\n",
    "         np.arange(t[\"freq\"].size)) / model.sinusoidal.frame_rate\n",
    "  plt.plot(t_t, t[\"mag\"] + 6.02, c=c, alpha=.33,\n",
    "           linewidth=3)  # compensate for spectral halving\n",
    "  plt.plot(t_x, 20 * np.log10(a * np.exp(-2 * t_x / d)), \"--\", c=c)\n",
    "\n",
    "plt.title(\"fitted curves\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"magnitude (dB)\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.legend([\"track\", \"fitted\"])\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency is simply estimated as the mean frequency of the peak track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resynthesize\n",
    "Let's resynthesize the sound using the estimated parameters (via additive synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_and_play(i: int, k: str, y: np.ndarray):\n",
    "  return ipd.display(ipd.HTML(f\"<h1>{k}</h1>\"),\n",
    "                     ipd.Audio(y, rate=fs, normalize=False))\n",
    "\n",
    "\n",
    "_, axs = plots.resynthesis(x, {\"Resynthesis\": model},\n",
    "                           tf_kws=dict(ylim=(0, 2000), aspect_ratio=1),\n",
    "                           foreach=label_and_play)\n",
    "resize(shape=(2, len(axs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeatsDROP\n",
    "We can also apply a regression algorithm to disentangle beating partials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sample.beatsdrop.regression\n",
    "from sample import beatsdrop as bd\n",
    "\n",
    "_, axs = plots.beatsdrop_comparison(model, {\n",
    "    \"BeatsDROP\": bd.regression.DualBeatRegression(),\n",
    "    \"Baseline\": bd.regression.BeatRegression(),\n",
    "},\n",
    "                                    x,\n",
    "                                    track_i=np.argmax(model.freqs_),\n",
    "                                    transpose=True)\n",
    "resize(7, 16 / 9, shape=axs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SAMPLEBeatsDROP` class integrates BeatsDROP and SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "model_bd = sample.SAMPLEBeatsDROP(**base.clone(model).get_params())\n",
    "model_bd.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plots.resynthesis(x, {\n",
    "    \"SAMPLE\": model,\n",
    "    \"SAMPLE+BeatsDROP\": model_bd\n",
    "},\n",
    "                           tf_kws=dict(ylim=(0, 2000), aspect_ratio=1),\n",
    "                           foreach=label_and_play)\n",
    "resize(4 * np.sqrt(2), shape=(2, len(axs) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9022f3c4e7ba04318b39ae85ed960c9e872f0a9af7db58b222b12617cf6d6cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
