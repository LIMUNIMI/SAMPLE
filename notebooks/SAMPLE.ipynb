{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Analysis for Modal Parameter Linear Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Install the `sample` package and its dependencies.\n",
    "The extras will install dependencies for helper functions such as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!$sys.executable -m pip install -qU lim-sample[notebooks,plots]==2.0.0\n",
    "from sample import __version__\n",
    "from sample.vid import logo\n",
    "print(\"SAMPLE version:\", __version__)\n",
    "logo(size_inches=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test audio\n",
    "We will synthesize a modal-like sound with three modal frequencies using simple additive synthesis.  \n",
    "Also, we will add a gaussian noise at -45 dB SNR to mimic a bad recording environment.  \n",
    "Sampling frequency is 44100 Hz and the duration is 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from librosa.display import waveshow, specshow\n",
    "from IPython import display as ipd\n",
    "from sample.sample import additive_synth\n",
    "from sample.utils import dsp as dsp_utils\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "@functools.wraps(ipd.Audio)\n",
    "def play(*args, **kwargs):\n",
    "  ipd.display(ipd.Audio(*args, **kwargs))\n",
    "\n",
    "def resize(w=12, h=6):\n",
    "  plt.gcf().set_size_inches([w, h])\n",
    "\n",
    "ground_truth = {\n",
    "  \"freqs\": [440, 1103, 1097],\n",
    "  \"decays\": [1, 0.75, 2],\n",
    "  \"amps\": [1, 0.8, 0.2],\n",
    "}\n",
    "ground_truth[\"amps\"] = np.array(ground_truth[\"amps\"]) / sum(ground_truth[\"amps\"])\n",
    "\n",
    "fs = 44100\n",
    "x = additive_synth(np.arange(int(2 * fs)) / fs, **ground_truth)\n",
    "\n",
    "# Add noise\n",
    "np.random.seed(42)\n",
    "x += np.random.randn(np.size(x)) * dsp_utils.db2a(-45)\n",
    "x /= np.max(np.abs(x))\n",
    "\n",
    "play(x, rate=fs)\n",
    "\n",
    "waveshow(x, sr=fs, alpha=.5, zorder=100)\n",
    "plt.grid()\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface\n",
    "Using the SAMPLE model is simplified by a scikit-learn-like API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import SAMPLE\n",
    "sample = SAMPLE(\n",
    "    sinusoidal_model__max_n_sines=10,\n",
    "    sinusoidal_model__peak_threshold=-30,\n",
    "    sinusoidal_model__save_intermediate=True\n",
    ").fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinusoidal Model\n",
    "SAMPLE is based on Serra's *Spectral Modelling Synthesis* (SMS),\n",
    "an analysis and synthesis system for musical sounds based\n",
    "on the decomposition of the sound into a deterministic\n",
    "sinusoidal and a stochastic component.\n",
    "\n",
    "The main components of the sinusoidal analysis are the peak detection\n",
    "and the peak continuation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT\n",
    "The peak detection/continuation algorithm is based on an analysis of the Short-Time Fourier Transform. Zero-phase windowing is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = np.array([\n",
    "  mx\n",
    "  for mx, _ in sample.sinusoidal_model.intermediate_[\"stft\"]\n",
    "]).T\n",
    "\n",
    "specshow(stft, sr=fs, x_axis=\"time\", y_axis=\"hz\");\n",
    "plt.ylim([0, 2000])\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak detection\n",
    "The peak detection algorithm detects peaks in each STFT frame of the analysed\n",
    "sound as a local maximum in the magnitude spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx, px = sample.sinusoidal_model.intermediate_[\"stft\"][0]\n",
    "f = fs * np.arange(mx.size) / sample.sinusoidal_model.w_.size\n",
    "ploc, pmag, pph = sample.sinusoidal_model.intermediate_[\"peaks\"][0]\n",
    "\n",
    "ax = plt.subplot(121)\n",
    "plt.fill_between(f, np.full(mx.shape, -120), mx, alpha=.1)\n",
    "plt.plot(f, mx)\n",
    "plt.scatter(ploc * fs / sample.sinusoidal_model.w_.size, pmag, c=\"C0\")\n",
    "plt.ylim([-60, plt.ylim()[1]])\n",
    "plt.grid()\n",
    "plt.title(\"magnitude\")\n",
    "\n",
    "plt.subplot(122, sharex=ax)\n",
    "plt.plot(f, px)\n",
    "plt.scatter(ploc * fs / sample.sinusoidal_model.w_.size, pph)\n",
    "plt.ylim([np.min(px[f < 2000]), np.max(px[f < 2000])])\n",
    "plt.grid()\n",
    "plt.title(\"phase\")\n",
    "plt.xlim([0, 2000])\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak continuation\n",
    "The peak continuation algorithm organizes the peaks into temporal tracks,\n",
    "with every track representing the time-varying behaviour of a partial.\n",
    "For every peak in a trajectory, the instantaneous frequency, magnitude\n",
    "and phase are stored to allow further manipulation and resynthesis.\n",
    "\n",
    "The general-purpose SMS method enables recycling of the peak tracks data structures: if one trajectory\n",
    "becomes inactive, it can be later picked up when a newly detected partial arises.\n",
    "Our implementation doesn't allow this.\n",
    "\n",
    "Moreover, two tracks that do not overlap in time but have approximately the same\n",
    "average frequency can be considered as belonging to the same partial and merged into the same track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import plots\n",
    "plots.sine_tracking_2d(sample.sinusoidal_model)\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import plots\n",
    "plots.sine_tracking_3d(sample.sinusoidal_model)\n",
    "resize(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Partials of a modal impact sound are characterized by exponentially decaying amplitudes.\n",
    "Our model for modal partials is\n",
    "$$x(t) = m\\cdot e^{-2\\frac{t}{d}}\\cdot \\sin{\\left(2\\pi f t + \\phi\\right)}$$\n",
    "\n",
    "The magnitude in decibels is a linear funtion of time\n",
    "$$m_{dB}(t) = 20\\log_{10}{\\left(m\\cdot e^{-2\\frac{t}{d}}\\right)} = 20\\log_{10}{m} - 40\\frac{\\log_{10}{e}}{d} \\cdot t$$\n",
    "\n",
    "$$k = - 40\\frac{\\log_{10}{e}}{d}$$\n",
    "$$q = 20\\log_{10}{m}$$\n",
    "\n",
    "$$m_{dB}(t) = kt + q$$\n",
    "\n",
    "We use linear regression to find an initial estimate of the parameters $k$ and $q$ from the magnitude tracks. Then, we refine the estimate by fitting a semi-linear *hinge* function. Amplitude is then doubled to compensate for the fact that we are looking at only half of the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = np.arange(x.size) / fs\n",
    "for i, ((f, d, a), t) in enumerate(zip(sample.param_matrix_.T, sample.sinusoidal_model.tracks_)):\n",
    "    c = \"C{}\".format(i)\n",
    "    t_t = (t[\"start_frame\"] + np.arange(t[\"freq\"].size)) * sample.sinusoidal_model.h / sample.sinusoidal_model.fs\n",
    "    plt.plot(t_t, t[\"mag\"] + 6.02, c=c, alpha=.33, linewidth=3)  # compensate for spectral halving\n",
    "    plt.plot(t_x, 20*np.log10(a * np.exp(-2*t_x / d)), \"--\", c=c)\n",
    "\n",
    "plt.title(\"fitted curves\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"magnitude (dB)\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.legend([\"track\", \"fitted\"])\n",
    "resize(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency is simply estimated as the mean frequency of the peak track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resynthesize\n",
    "Let's resynthesize the sound using the estimated parameters (via additive synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa import stft, amplitude_to_db\n",
    "\n",
    "x_hat = sample.predict(np.arange(x.size) / fs)\n",
    "\n",
    "ax = plt.subplot(211)\n",
    "x_dual = np.array([x, x_hat])\n",
    "for l, xi in zip((\"Original\", \"Resynthesis\"), x_dual):\n",
    "    waveshow(xi, sr=fs, alpha=.5, zorder=100, label=l, ax=ax)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "X_db = amplitude_to_db(np.abs(stft(x)), ref=np.max)\n",
    "ax = plt.subplot(223, sharex=ax)\n",
    "specshow(X_db, ax=ax, sr=fs, x_axis=\"time\", y_axis=\"hz\")\n",
    "ax.set_title(\"Original\")\n",
    "\n",
    "X_hat_db = amplitude_to_db(np.abs(stft(x_hat)), ref=np.max)\n",
    "ax = plt.subplot(224, sharex=ax, sharey=ax)\n",
    "specshow(X_hat_db, ax=ax, sr=fs, x_axis=\"time\", y_axis=\"hz\")\n",
    "ax.set_title(\"Resynthesis\")\n",
    "ax.set_ylim([0, 2000])\n",
    "\n",
    "resize(12, 12)\n",
    "ipd.display(ipd.HTML(\"Original\"))\n",
    "play(x, rate=fs)\n",
    "ipd.display(ipd.HTML(\"Resynthesis\"))\n",
    "play(x_hat, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeatsDROP\n",
    "We can also apply a regression algorithm to disentangle beating partials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.beatsdrop import regression as beatsdrop_regression\n",
    "import itertools\n",
    "\n",
    "# Extract one sinusoidal track (the beating one)\n",
    "track_i = np.argmax(sample.freqs_)\n",
    "track = sample.sinusoidal_model.tracks_[track_i]\n",
    "track_t = np.arange(\n",
    "    len(track[\"mag\"]\n",
    "        )) * sample.sinusoidal_model.h / sample.sinusoidal_model.fs\n",
    "track_a = track[\"mag\"] + 6.02\n",
    "track_f = track[\"freq\"]\n",
    "if sample.sinusoidal_model.reverse:\n",
    "  track_a = np.flip(track_a)\n",
    "  track_f = np.flip(track_f)\n",
    "iok = np.isfinite(track_a)\n",
    "\n",
    "track_alin = track_a.copy()\n",
    "track_alin[iok] = dsp_utils.db2a(track_a[iok])\n",
    "\n",
    "# Apply both variants regression\n",
    "br = beatsdrop_regression.BeatRegression(fs=fs, lpf=20)\n",
    "dbr = beatsdrop_regression.DualBeatRegression(fs=fs, lpf=20)\n",
    "for b in (br, dbr):\n",
    "  b.fit(t=track_t[iok], a=track_a[iok], f=track_f[iok])\n",
    "\n",
    "# Plot\n",
    "_, axs = plt.subplots(3, 2, sharex=True, sharey=\"row\", figsize=np.array((16/9 * 2, 1 * 3)) * 6)\n",
    "\n",
    "for i, b in enumerate((dbr, br)):\n",
    "  am_, a0_, a1_, fm_ = b.predict(track_t, \"am\", \"a0\", \"a1\", \"fm\")\n",
    "  np.true_divide(fm_, 2 * np.pi, out=fm_)\n",
    "\n",
    "  # Amplitude modulation\n",
    "  axs[0][i].plot(np.arange(x.size) / fs, x, c=\"C0\", alpha=0.25, label=\"Signal\")\n",
    "  for a, kw in (\n",
    "      (track_alin, dict(c=\"C0\", label=\"Sinusoidal Track\", zorder=102)),\n",
    "      (am_, dict(linestyle=\"--\", c=\"C1\", label=\"Prediction\", zorder=102)),\n",
    "      (a0_, dict(c=\"C3\", label=\"$A_1$\", zorder=101)),\n",
    "      (a1_, dict(c=\"C4\", label=\"$A_2$\", zorder=101)),\n",
    "  ):\n",
    "    a_ = np.copy(a)\n",
    "    a_[np.less_equal(a, dsp_utils.db2a(-60))] = np.nan\n",
    "    axs[0][i].plot(track_t, a, **kw)\n",
    "    axs[1][i].plot(track_t, dsp_utils.a2db(a_), **kw)\n",
    "\n",
    "  if i == 0:\n",
    "    axs[0][i].set_ylabel(\"amplitude\")\n",
    "    axs[1][i].set_ylabel(\"amplitude (dB)\")\n",
    "  axs[0][0].set_title(\"BeatsDROP\")\n",
    "  axs[0][1].set_title(\"Baseline\")\n",
    "\n",
    "  # Frequency modulation\n",
    "  axs[2][i].plot(track_t, track_f, c=\"C0\", zorder=3, label=\"Sinusoidal Track\")\n",
    "  axs[2][i].plot(track_t, fm_, \"--\", c=\"C1\", zorder=5, label=\"Prediction\")\n",
    "  axs[2][i].plot(track_t,\n",
    "                 np.full_like(track_t, b.params_[2]),\n",
    "                 c=\"C3\",\n",
    "                 label=r\"$\\nu_1$\",\n",
    "                 zorder=4)\n",
    "  axs[2][i].plot(track_t,\n",
    "                 np.full_like(track_t, b.params_[3]),\n",
    "                 c=\"C4\",\n",
    "                 label=r\"$\\nu_2$\",\n",
    "                 zorder=4)\n",
    "  if i == 0:\n",
    "    axs[2][i].set_ylabel(\"frequency (Hz)\")\n",
    "\n",
    "for ax in itertools.chain.from_iterable(axs):\n",
    "  ax.legend(loc=\"upper right\")\n",
    "  ax.grid()\n",
    "  yl = ax.get_ylabel()\n",
    "  if yl:\n",
    "    yl = ax.set_ylabel(yl)\n",
    "    yl.set_rotation(0)\n",
    "    yl.set_horizontalalignment(\"left\")\n",
    "    yl.set_verticalalignment(\"bottom\")\n",
    "    ax.yaxis.set_label_coords(-0.05, 1.01)\n",
    "for c in range(axs.shape[0]):\n",
    "  axs[c, -1].set_xlabel(\"time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now hear the refined result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.beatsdrop.regression import BeatRegression\n",
    "\n",
    "idxs = np.arange(len(sample.freqs_) - 1)\n",
    "idxs[track_i:] += 1\n",
    "\n",
    "ipd.display(ipd.HTML(\"Original\"))\n",
    "play(x, rate=fs)\n",
    "_, axs = plt.subplots(3, 1, sharex=True, figsize=np.array((16 / 9, 1 * 3)) * 6)\n",
    "waveshow(x, ax=axs[0], sr=fs, alpha=.5, zorder=100)\n",
    "axs[0].set_title(\"Original\")\n",
    "\n",
    "br_params = {}\n",
    "for i, (k, b, ax) in enumerate(zip((\"Baseline\", \"BeatsDROP\"), (br, dbr), axs[1:])):\n",
    "  d = {}\n",
    "  br_params[k] = d\n",
    "  d[\"freqs\"] = [*sample.freqs_[idxs], *b.params_[2:4]]\n",
    "  d[\"decays\"] = [*sample.decays_[idxs], *b.params_[4:6]]\n",
    "  d[\"amps\"] = [*sample.amps_[idxs], *b.params_[:2]]\n",
    "  d[\"phases\"] = [*np.full_like(idxs, 0), *b.params_[6:8]]\n",
    "  \n",
    "  x_b = additive_synth(np.arange(x.size) / fs, **d)\n",
    "  ipd.display(ipd.HTML(k))\n",
    "  play(x_b, rate=fs)\n",
    "  waveshow(x_b, sr=fs, ax=ax, alpha=.5, zorder=100, color=f\"C{i + 1}\")\n",
    "  ax.set_title(k)\n",
    "\n",
    "for ax in axs:\n",
    "  ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
