{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE Tutorial\n",
    "In this notebook we will see how to apply the SAMPLE model to a real-life audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Install the `sample` package and its dependencies.\n",
    "The extras will install dependencies for helper functions such as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!$sys.executable -m pip install -qU lim-sample[notebooks,plots]==2.1.0\n",
    "import sample\n",
    "\n",
    "sample(logo=dict(size_inches=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio\n",
    "Download the test audio or load your own audio file. In this notebook, you can specify\n",
    "\n",
    "   - a filename: to load the audio from file\n",
    "   - a URL: to download the audio file from the web (only if fname is empty)\n",
    "   - start time and length (in seconds): to cut the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from IPython import display as ipd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "def resize(diag: float = 8.485, aspect: float = 1, shape=(1, 1)):\n",
    "  plt.gcf().set_size_inches(\n",
    "      diag * np.true_divide([aspect, 1], np.sqrt(aspect * aspect + 1)) *\n",
    "      np.flip(shape))\n",
    "\n",
    "\n",
    "fname = \"\"  #@param {type: \"string\"}\n",
    "url = \"https://gist.github.com/ChromaticIsobar/dcde518ec070b38312ef048f472d92aa/raw/3a69a5c6285f4516bae840eb565144772e8809ae/glass.wav\"  #@param {type: \"string\"}\n",
    "start_time = 7.65  #@param {type: \"number\"}\n",
    "time_length = 2.56  #@param {type: \"number\"}\n",
    "\n",
    "if not fname:\n",
    "  _fname = \"_testaudio.wav\"\n",
    "  r = requests.get(url)\n",
    "  with open(_fname, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "else:\n",
    "  _fname = fname\n",
    "\n",
    "fs, x = wavfile.read(_fname)\n",
    "if not fname:\n",
    "  os.remove(_fname)\n",
    "x = x / -np.iinfo(x.dtype).min\n",
    "\n",
    "i_0 = int(start_time * fs)\n",
    "i_1 = i_0 + int(time_length * fs)\n",
    "\n",
    "x = x[i_0:i_1]\n",
    "t = np.arange(x.size) / fs\n",
    "\n",
    "ipd.display(ipd.Audio(x, rate=fs))\n",
    "\n",
    "plt.plot(t, x, alpha=.5, zorder=100)\n",
    "plt.grid()\n",
    "resize(aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SAMPLE object\n",
    "Apply SAMPLE to the audio file\n",
    "\n",
    "**Hint**: start with a small number of sines (e.g. `sinusoidal__tracker__max_n_sines=8`) and progressively increase it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "model = sample.SAMPLEBeatsDROP(\n",
    "    sinusoidal__tracker__max_n_sines=8,\n",
    "    sinusoidal__tracker__frequency_bounds=(600, 20e3),\n",
    "    sinusoidal__tracker__reverse=True,\n",
    "    # Keep this for better plots\n",
    "    beat_decisor__intermediate__save=True,\n",
    ")\n",
    "model.fit(x, sinusoidal__tracker__fs=fs, n_jobs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare\n",
    "We can additively render audio from the model to get an idea of how SAMPLE has modelled the audio.  \n",
    "You can listen to the original and resynthesized sounds and plot their STFTs side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import plots\n",
    "\n",
    "\n",
    "def label_and_play(i: int, k: str, y: np.ndarray):\n",
    "  return ipd.display(ipd.HTML(f\"<h1>{k}</h1>\"),\n",
    "                     ipd.Audio(np.clip(y, -1, 1), rate=fs, normalize=False))\n",
    "\n",
    "\n",
    "fig, axs = plots.resynthesis(x, {\n",
    "    \"SAMPLE\": model,\n",
    "},\n",
    "                             db_floor=-120,\n",
    "                             foreach=label_and_play)\n",
    "axs[0].set_ylim(-1.05, 1.05)\n",
    "resize(aspect=1, shape=(2, len(axs) - 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Visualize tracked partials, then go back and adjust SAMPLE parameters to better model your audio.  \n",
    "Note that, if `beat_decisor__intermediate__save` is `True`, then the detected beating trajectories are shown as dashed lines in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.utils import dsp\n",
    "from scipy import signal\n",
    "\n",
    "_, axs = plt.subplots(1, 2, sharex=True, squeeze=False)\n",
    "stft_f, stft_t, stft = signal.stft(x, fs=fs, nperseg=1 << 10)\n",
    "stft_db = dsp.complex2db(stft, floor=-180, floor_db=True)\n",
    "\n",
    "plots.sine_tracking_2d(model, ax=axs[0, :], zorder=102)\n",
    "plots.tf_plot(stft_db,\n",
    "              tlim=stft_t[[0, -1]],\n",
    "              flim=stft_f[[0, -1]],\n",
    "              ax=axs[0, 0],\n",
    "              aspect_ratio=1,\n",
    "              cmap=\"Greys\",\n",
    "              zorder=100,\n",
    "              ylim=model.sinusoidal.tracker.frequency_bounds)\n",
    "resize(aspect=1, shape=np.shape(axs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust\n",
    "Now, go back and adjust the parameters.\n",
    "Some common parameters that you could want to tweak are\n",
    "\n",
    "- `sinusoidal__tracker__max_n_sines`: the number of concurrent partials\n",
    "- `sinusoidal__t`: threshold for peak detection (dB)\n",
    "- `sinusoidal__tracker__peak_threshold`: threshold for the magnitude intercept (dB at time=0)\n",
    "- `sinusoidal__tracker__freq_dev_offset` and `sinusoidal__tracker__freq_dev_slope`: they control the frequency deviation threshold for the peak continuation. Threshold at frequency $f$ is $\\text{offset}+\\text{slope}\\cdot f$\n",
    "\n",
    "Below, all parameters and their current values are nested in an interactive HTML list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.ipython import CollapsibleModelParams\n",
    "\n",
    "CollapsibleModelParams(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Hint</b>: Click here for some curated parameters for this test sound</summary>\n",
    "\n",
    "  ```python\n",
    "      sinusoidal__tracker__max_n_sines=128,\n",
    "      sinusoidal__n=1024,\n",
    "      sinusoidal__w=signal.blackmanharris(1024),\n",
    "      sinusoidal__tracker__h=64,\n",
    "      sinusoidal__tracker__frequency_bounds=(600, 20e3),\n",
    "      sinusoidal__tracker__reverse=True,\n",
    "      sinusoidal__tracker__min_sine_dur=0.1,\n",
    "      sinusoidal__tracker__strip_t=0.5,\n",
    "      sinusoidal__tracker__peak_threshold=-60.0,\n",
    "      sinusoidal__t=-75.0,\n",
    "  ```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "Once you are happy with your model, you can export the parameters in a JSON file for loading [*Sound Design Toolkit*](https://github.com/SkAT-VG/SDT)'s (SDT) `modal` objects.  \n",
    "Specify a file to save the JSON string, otherwise, print it to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "json_file = \"\"  #@param {type: \"string\"}\n",
    "\n",
    "# You can also manipulate the parameters here\n",
    "_model = copy.deepcopy(model)\n",
    "_model.amps_ *= 200\n",
    "\n",
    "params = _model.sdt_params_()\n",
    "\n",
    "if json_file:\n",
    "  with open(json_file, \"w\") as f:\n",
    "    json.dump(\n",
    "        params,\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "else:\n",
    "  print(json.dumps(params, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
