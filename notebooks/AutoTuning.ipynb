{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Tuning of SAMPLE hyperparameters\n",
    "In this notebook we will see how to automatically tune the hyperparameters of SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Install the `sample` package and its dependencies.\n",
    "The extras will install dependencies for helper functions such as plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!$sys.executable -m pip install -qU lim-sample[notebooks,plots]==2.2.0\n",
    "import sample\n",
    "\n",
    "sample(logo=dict(size_inches=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio\n",
    "Download the test audio or load your own audio file. In this notebook, you can specify\n",
    "\n",
    "   - a filename: to load the audio from file\n",
    "   - a URL: to download the audio file from the web (only if fname is empty)\n",
    "   - start time and length (in seconds): to cut the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from IPython import display as ipd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "def resize(diag: float = 8.485, aspect: float = 1, shape=(1, 1)):\n",
    "  plt.gcf().set_size_inches(\n",
    "      diag * np.true_divide([aspect, 1], np.sqrt(aspect * aspect + 1)) *\n",
    "      np.flip(shape))\n",
    "\n",
    "\n",
    "fname = \"\"  #@param {type: \"string\"}\n",
    "url = \"https://gist.github.com/ChromaticIsobar/dcde518ec070b38312ef048f472d92aa/raw/3a69a5c6285f4516bae840eb565144772e8809ae/glass.wav\"  #@param {type: \"string\"}\n",
    "start_time = 7.65  #@param {type: \"number\"}\n",
    "time_length = 2.56  #@param {type: \"number\"}\n",
    "\n",
    "if fname:\n",
    "  fs, x = wavfile.read(fname)\n",
    "else:\n",
    "  r = requests.get(url)\n",
    "  with io.BytesIO() as buf:\n",
    "    buf.write(r.content)\n",
    "    del r\n",
    "    buf.seek(0)\n",
    "    fs, x = wavfile.read(buf)\n",
    "x = x / -np.iinfo(x.dtype).min\n",
    "\n",
    "i_0 = int(start_time * fs)\n",
    "i_1 = i_0 + int(time_length * fs)\n",
    "\n",
    "x = x[i_0:i_1]\n",
    "t = np.arange(x.size) / fs\n",
    "\n",
    "ipd.display(ipd.Audio(x, rate=fs))\n",
    "\n",
    "plt.plot(t, x, alpha=.5, zorder=100)\n",
    "plt.grid()\n",
    "resize(aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find a set of parameter values for the `SAMPLE` algorithm such that it produces an output audio as similar as possible to the input.  \n",
    "Let's list all available parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define some parameters to be fixed, and not be tuned by the optimizer.\n",
    "We will put a limit on the maximum number of synthesized modes (`max_n_modes=64`) to avoid excessive overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.ipython import CollapsibleModelParams\n",
    "import sample\n",
    "\n",
    "base_model = sample.SAMPLEBeatsDROP(\n",
    "    max_n_modes=32,\n",
    "    sinusoidal__tracker__strip_t=0.5,\n",
    "    sinusoidal__tracker__peak_threshold=-60.0,\n",
    "    sinusoidal__tracker__reverse=True,\n",
    "    sinusoidal__tracker__frequency_bounds=(100, 20e3),\n",
    ")\n",
    "CollapsibleModelParams(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the space of the parameters to be tuned. We will automatically adjust\n",
    " - the logarithm of the FFT size\n",
    " - the number of sinusoidal peaks per window\n",
    " - the threshold for peak detection\n",
    " - the minimum trajectory duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt.space\n",
    "\n",
    "sample_opt_space = dict(\n",
    "    sinusoidal__log_n=skopt.space.Integer(6, 14, name=\"log2(n)\"),\n",
    "    sinusoidal__tracker__max_n_sines=skopt.space.Integer(32,\n",
    "                                                         256,\n",
    "                                                         name=\"n sines\"),\n",
    "    sinusoidal__t=skopt.space.Real(-120, -45, name=\"fft threshold\"),\n",
    "    sinusoidal__tracker__min_sine_dur=skopt.space.Real(0,\n",
    "                                                       0.5,\n",
    "                                                       name=\"min duration\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the cochleagram to define an objective function.  \n",
    "The difference between the input audio's cochleagram and the output's will quantify how dissimilar are the two sounds.  \n",
    "This is the value we want the optimizer to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.evaluation.metrics import CochleagramLoss\n",
    "from sample.utils.dsp import complex2db\n",
    "from functools import partial\n",
    "\n",
    "cochleagram_loss = CochleagramLoss(fs=fs,\n",
    "                                   normalize=True,\n",
    "                                   analytical=\"ir\",\n",
    "                                   stride=int(fs * 0.008),\n",
    "                                   postprocessing=partial(complex2db,\n",
    "                                                          floor=-60,\n",
    "                                                          floor_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize\n",
    "Run the optimization procedure.\n",
    "Depending on the number of iterations, this could take a couple or more minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import sample.optimize\n",
    "\n",
    "#@markdown Check this to restart the optimization from scratch\n",
    "reset = True  #@param {type:\"boolean\"}\n",
    "#@markdown ---\n",
    "#@markdown Number of optimization iterations\n",
    "n_minimizing_points = 32  #@param {type:\"integer\"}\n",
    "#@markdown Number of exploratory iterations\n",
    "n_initial_points = 32  #@param {type:\"integer\"}\n",
    "#@markdown ---\n",
    "#@markdown Random seed\n",
    "seed = 42  #@param {type:\"integer\"}\n",
    "\n",
    "# Setup optimizer\n",
    "n_calls = n_minimizing_points + n_initial_points\n",
    "if reset or \"opt_res\" not in locals():\n",
    "  opt_res = None\n",
    "sample_opt = sample.optimize.SAMPLEOptimizer(\n",
    "    model=base_model,\n",
    "    loss_fn=cochleagram_loss,\n",
    "    **sample_opt_space,\n",
    ")\n",
    "\n",
    "# This is only needed to make the progressbar\n",
    "tqdm_cbk = sample.optimize.TqdmCallback(\n",
    "    sample_opt=sample_opt,\n",
    "    n_calls=n_calls,\n",
    "    n_initial_points=n_initial_points,\n",
    "    tqdm_fn=tqdm_notebook,\n",
    ")\n",
    "\n",
    "opt_model, opt_res = sample_opt.gp_minimize(x=x,\n",
    "                                            fs=fs,\n",
    "                                            n_calls=n_calls,\n",
    "                                            n_initial_points=n_initial_points,\n",
    "                                            callback=tqdm_cbk,\n",
    "                                            initial_point_generator=\"lhs\",\n",
    "                                            acq_func=\"LCB\",\n",
    "                                            state=opt_res,\n",
    "                                            random_state=seed,\n",
    "                                            fit_kws=dict(n_jobs=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen back\n",
    "Listen to an additive resynthesis of the sound based on the estimated modal parameters.\n",
    "You can change the number of synthesized modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.ipython import LabelAndPlayForeach\n",
    "from sample import plots\n",
    "\n",
    "#@markdown Number of modes for resynthesis\n",
    "n_modes = 32  #@param {type:\"integer\"}\n",
    "\n",
    "n_modes_old = opt_model.get_params()[\"max_n_modes\"]\n",
    "opt_model.set_params(max_n_modes=n_modes)\n",
    "\n",
    "fig, axs = plots.resynthesis(\n",
    "    x,\n",
    "    models={\"SAMPLE\": opt_model},\n",
    "    db_floor=-120,\n",
    "    foreach=LabelAndPlayForeach(audio_kws=dict(rate=fs)))\n",
    "opt_model.set_params(max_n_modes=n_modes_old)\n",
    "axs[0].set_ylim(-1.05, 1.05)\n",
    "resize(aspect=1, shape=(2, len(axs) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
